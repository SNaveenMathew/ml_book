Disclaimer: This topic is not mathematically rigorous, has some strong opinions, and may not represent the state-of-the-art

# LLMs are bad

Opinion: My first ever course in NLP was taught by a computational linguist. Therefore I have an inclination towards 'structure-first' type of language models, even though they don't approximate the true process of language generation (during training or 'in-sample' after convergence of training) very well.

# LLMs are actually useful

When I first self-learnt the topic 'reinforcement learning' in 2018-19, I repeatedly heard the word 'duct tape' when there was a discussion on the algorithms (algorithm A is a duct tape on algorithm B, which in turn is a duct tape on algorithm C, ...). I simultaneously found [this page](https://www.facebook.com/profile.php?id=100066295433994), which I visited every day for some fun.